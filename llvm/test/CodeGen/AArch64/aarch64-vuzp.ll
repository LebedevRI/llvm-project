; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=aarch64-none-linux-gnu -mattr=+neon < %s | FileCheck %s

declare <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8>, <16 x i8>)

; CHECK-LABEL: fun1:
; CHECK: uzp1 {{v[0-9]+}}.8b, {{v[0-9]+}}.8b, {{v[0-9]+}}.8b
define i32 @fun1() {
; CHECK-LABEL: fun1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    adrp x8, .LCPI0_0
; CHECK-NEXT:    ldr q0, [x8, :lo12:.LCPI0_0]
; CHECK-NEXT:    tbl v0.16b, { v0.16b }, v0.16b
; CHECK-NEXT:    ext v1.16b, v0.16b, v0.16b, #8
; CHECK-NEXT:    uzp1 v0.8b, v0.8b, v1.8b
; CHECK-NEXT:    str d0, [x8]
; CHECK-NEXT:    ret
entry:
  %vtbl1.i.1 = tail call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> <i8 0, i8 16, i8 19, i8 4, i8 -65, i8 -65, i8 -71, i8 -71, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> undef)
  %vuzp.i212.1 = shufflevector <16 x i8> %vtbl1.i.1, <16 x i8> undef, <8 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 14>
  %scevgep = getelementptr <8 x i8>, ptr undef, i64 1
  store <8 x i8> %vuzp.i212.1, ptr %scevgep, align 1
  ret i32 undef
}

; CHECK-LABEL: fun2:
; CHECK: uzp2 {{v[0-9]+}}.8b, {{v[0-9]+}}.8b, {{v[0-9]+}}.8b
define i32 @fun2() {
; CHECK-LABEL: fun2:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    adrp x8, .LCPI1_0
; CHECK-NEXT:    ldr q0, [x8, :lo12:.LCPI1_0]
; CHECK-NEXT:    tbl v0.16b, { v0.16b }, v0.16b
; CHECK-NEXT:    ext v1.16b, v0.16b, v0.16b, #8
; CHECK-NEXT:    uzp2 v0.8b, v0.8b, v1.8b
; CHECK-NEXT:    str d0, [x8]
; CHECK-NEXT:    ret
entry:
  %vtbl1.i.1 = tail call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> <i8 0, i8 16, i8 19, i8 4, i8 -65, i8 -65, i8 -71, i8 -71, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> undef)
  %vuzp.i212.1 = shufflevector <16 x i8> %vtbl1.i.1, <16 x i8> undef, <8 x i32> <i32 1, i32 3, i32 5, i32 7, i32 9, i32 11, i32 13, i32 15>
  %scevgep = getelementptr <8 x i8>, ptr undef, i64 1
  store <8 x i8> %vuzp.i212.1, ptr %scevgep, align 1
  ret i32 undef
}

; CHECK-LABEL: fun3:
; CHECK-NOT: uzp1
define i32 @fun3() {
; CHECK-LABEL: fun3:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    adrp x8, .LCPI2_0
; CHECK-NEXT:    ldr q0, [x8, :lo12:.LCPI2_0]
; CHECK-NEXT:    adrp x8, .LCPI2_1
; CHECK-NEXT:    tbl v0.16b, { v0.16b }, v0.16b
; CHECK-NEXT:    ldr d1, [x8, :lo12:.LCPI2_1]
; CHECK-NEXT:    tbl v0.8b, { v0.16b }, v1.8b
; CHECK-NEXT:    str d0, [x8]
; CHECK-NEXT:    ret
entry:
  %vtbl1.i.1 = tail call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> <i8 0, i8 16, i8 19, i8 4, i8 -65, i8 -65, i8 -71, i8 -71, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> undef)
  %vuzp.i212.1 = shufflevector <16 x i8> %vtbl1.i.1, <16 x i8> undef, <8 x i32> <i32 0, i32 2, i32 4, i32 6, i32 8, i32 10, i32 12, i32 15>
  %scevgep = getelementptr <8 x i8>, ptr undef, i64 1
  store <8 x i8> %vuzp.i212.1, ptr %scevgep, align 1
  ret i32 undef
}

; CHECK-LABEL: fun4:
; CHECK-NOT: uzp2
define i32 @fun4() {
; CHECK-LABEL: fun4:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    adrp x8, .LCPI3_0
; CHECK-NEXT:    ldr q0, [x8, :lo12:.LCPI3_0]
; CHECK-NEXT:    adrp x8, .LCPI3_1
; CHECK-NEXT:    tbl v0.16b, { v0.16b }, v0.16b
; CHECK-NEXT:    ldr d1, [x8, :lo12:.LCPI3_1]
; CHECK-NEXT:    tbl v0.8b, { v0.16b }, v1.8b
; CHECK-NEXT:    str d0, [x8]
; CHECK-NEXT:    ret
entry:
  %vtbl1.i.1 = tail call <16 x i8> @llvm.aarch64.neon.tbl1.v16i8(<16 x i8> <i8 0, i8 16, i8 19, i8 4, i8 -65, i8 -65, i8 -71, i8 -71, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> undef)
  %vuzp.i212.1 = shufflevector <16 x i8> %vtbl1.i.1, <16 x i8> undef, <8 x i32> <i32 3, i32 3, i32 5, i32 7, i32 9, i32 11, i32 13, i32 15>
  %scevgep = getelementptr <8 x i8>, ptr undef, i64 1
  store <8 x i8> %vuzp.i212.1, ptr %scevgep, align 1
  ret i32 undef
}

; CHECK-LABEL: pr36582:
; Check that this does not ICE.
define void @pr36582(ptr %p1, ptr %p2) {
; CHECK-LABEL: pr36582:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    ldr d0, [x0]
; CHECK-NEXT:    movi v1.2d, #0x0000ff000000ff
; CHECK-NEXT:    ushll v0.4s, v0.4h, #0
; CHECK-NEXT:    and v0.16b, v0.16b, v1.16b
; CHECK-NEXT:    str q0, [x1]
; CHECK-NEXT:    ret
entry:
  %wide.vec = load <8 x i8>, ptr %p1, align 1
  %strided.vec = shufflevector <8 x i8> %wide.vec, <8 x i8> undef, <4 x i32> <i32 0, i32 2, i32 4, i32 6>
  %y = zext <4 x i8> %strided.vec to <4 x i32>
  store <4 x i32> %y, ptr %p2, align 4
  ret void
}

; Check that this pattern is recognized as a VZIP and
; that the vector blend transform does not scramble the pattern.
; CHECK-LABEL: vzipNoBlend:
; CHECK: zip1
define <8 x i8> @vzipNoBlend(ptr %A, ptr %B) nounwind {
; CHECK-LABEL: vzipNoBlend:
; CHECK:       // %bb.0:
; CHECK-NEXT:    ldr d0, [x0]
; CHECK-NEXT:    adrp x8, .LCPI5_0
; CHECK-NEXT:    mov v0.d[1], v0.d[0]
; CHECK-NEXT:    ldr d1, [x8, :lo12:.LCPI5_0]
; CHECK-NEXT:    tbl v0.8b, { v0.16b }, v1.8b
; CHECK-NEXT:    ret
  %t = load <8 x i8>, ptr %A
  %vzip = shufflevector <8 x i8> %t, <8 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  ret <8 x i8> %vzip
}
